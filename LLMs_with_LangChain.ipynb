{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRSMlEE5MKDzLEY+9TCy0t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumitsaurabhss/ai-with-python/blob/main/LLMs_with_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\")"
      ],
      "metadata": {
        "id": "z1Kz9c41khRP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "rBEfrNe0s_LS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9m_Ozgxed_9C"
      },
      "outputs": [],
      "source": [
        "#!pip install langchain-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint"
      ],
      "metadata": {
        "id": "AWViICffhsdV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_key = userdata.get('HF_Key')"
      ],
      "metadata": {
        "id": "H8I9SM4ghXbf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id='tiiuae/falcon-7b-instruct',\n",
        "    huggingfacehub_api_token = hf_key\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj5NRckzjJCx",
        "outputId": "89c5a95e-d875-4308-d681-7bbd8ef4bb22"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = 'Can you still have fun'\n",
        "output = llm.invoke(question)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcse53A9q1Xx",
        "outputId": "dac45eea-19bd-49f7-eae3-80d46b0d7e50"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " on a budget? Here are 10 free and affordable activities to do with kids\n",
            "You don't have to break the bank to have fun with your children. Here are 10 free and affordable activities to do with kids\n",
            "There are plenty of ways to have a fun, budget-friendly family day.\n",
            "We've rounded up 10 ideas for low-cost entertainment that will help you create great memories with your kids.\n",
            "If you're looking for ways to spend quality time with your children during a pandemic, these free and affordable ideas can help.\n",
            "1. Museums\n",
            "Kids love learning about history, science, and the arts. Most museums offer free admission for children 12 and younger, and many have free events on weekends and during the week. Check out their websites for free admission days and other activities.\n",
            "2. Parks\n",
            "Whether it's for a picnic or to play on the playground, parks are a great way to spend a few hours with your kids. Look for free or low-cost activities and events in your local area.\n",
            "3. Playgrounds\n",
            "Children love to play. You can find free or low-cost playgrounds in your area. Just do a quick search on Google Maps or other search engines for nearby playgrounds.\n",
            "4. Libraries\n",
            "Children's libraries are a great place to take kids on a low-cost date. They offer free books, movies, and other activities. Check with your local library to see what types of events they offer.\n",
            "5. Kids' Days at Events\n",
            "Many festivals, fairs, and events offer free children's activities. Check out their websites to see what events are happening in your area.\n",
            "6. Family-Friendly Hiking\n",
            "Kids love to be outdoors. Look for free or low-cost family-friendly hiking trails in your area.\n",
            "7. Beach Days\n",
            "The beach is a great way to spend a summer day. Check with your local town or city to see what beach events or activities are free or low-cost.\n",
            "8. Mini-Cycling or Skateboarding\n",
            "Kids love to get active. You can find free or low-cost mini-biking and skateboarding activities in your area.\n",
            "9. Aquariums\n",
            "Aquariums are a great way to learn about marine life. Check their websites for free admission days or low-cost tickets.\n",
            "10. Family-Friendly Music Festivals\n",
            "Children love to sing and dance. You can find low-cost or free family-friendly music festivals and concerts in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del llm"
      ],
      "metadata": {
        "id": "xsD1YrWKsGgC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flEm-ymNtPFi",
        "outputId": "0de536c4-8bf8-4ede-fcc8-3e3abede8d84"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install langchain-openai"
      ],
      "metadata": {
        "id": "UgK4LNB_tRvn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI"
      ],
      "metadata": {
        "id": "5Fo3cpklujw3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(\n",
        "    model_name=\"gpt-3.5-turbo-instruct\",\n",
        "    openai_api_key=userdata.get('OpenAI_Key')\n",
        ")"
      ],
      "metadata": {
        "id": "-oiRbSErusjO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#question = 'Can you still have fun'\n",
        "#output = llm.invoke(question)\n",
        "\n",
        "#print(output)"
      ],
      "metadata": {
        "id": "inECqG_PzdJV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del llm"
      ],
      "metadata": {
        "id": "vm1lv9ryzkyb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "797l-2W61jG-",
        "outputId": "5620118c-f74a-45fe-aa9a-ce2acd3efa6a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "808"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lOwt8CTY1mQZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prompt Templates"
      ],
      "metadata": {
        "id": "tigMIm5DbRjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "0pme4pYXbT4V"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = 'You are an artificial intelligence assistant, answer the question. {question}'"
      ],
      "metadata": {
        "id": "w_G9PBQvbeEl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(template=template, input_variables=['question'])"
      ],
      "metadata": {
        "id": "49lquZZwb3Hb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt_template.invoke({'question': 'What is LangChain?'}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuYsM0QHcNVb",
        "outputId": "de6ff907-4045-4d57-b122-dc437538ea7e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text='You are an artificial intelligence assistant, answer the question. What is LangChain?'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install langchain-community"
      ],
      "metadata": {
        "id": "8Pk2psRGc6O2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import HuggingFaceHub"
      ],
      "metadata": {
        "id": "JBhAI9G6cbuF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id='tiiuae/falcon-7b-instruct',\n",
        "    huggingfacehub_api_token = hf_key\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2wXfEHsc3W9",
        "outputId": "014248c6-8251-426d-b364-da67c0410691"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = prompt_template | llm"
      ],
      "metadata": {
        "id": "HWrvTCQme7GG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = 'How does LangChain make LLM application development easier?'"
      ],
      "metadata": {
        "id": "OCvWpNAOfbG1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm_chain.invoke({'question': question}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1ndnJyrfgsm",
        "outputId": "63fdebb3-791e-48da-f23c-4b3c02fdb8bf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LangChain simplifies LLM application development by providing a powerful natural language processing (NLP) platform that can understand complex legal language. Our advanced machine learning algorithms enable lawyers and legal professionals to easily create, maintain, and update legal documents, contracts, and templates. By leveraging our language models and deep learning technologies, users can save time, reduce errors, and increase accuracy in their work, ultimately increasing productivity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t3CBIGAofrAr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chat Models"
      ],
      "metadata": {
        "id": "aT5rBx8EgJq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "id": "pudsvG4WgMkv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        ('system', 'You are soto zen master Roshi.'),\n",
        "        ('human', 'What is the essence of Zen?'),\n",
        "        ('ai', 'When you are hungry, eat. When you are tired, sleep.'),\n",
        "        ('human', 'Respond to the question: {question}')\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "2IdoZAOZgXLx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "q5ngphD_hGTU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0, openai_api_key=userdata.get('OpenAI_Key'))"
      ],
      "metadata": {
        "id": "0HeDv40_hdXW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = prompt_template | llm"
      ],
      "metadata": {
        "id": "LOZEZQwEhrxZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#question = 'What is the sound of one hand clapping?'\n",
        "#response = llm_chain.invoke({'question': question})\n",
        "#print(response.content)\n",
        "#response = llm_chain.invoke({'question': 'How can I retain learning?'})\n",
        "#print(response.content)"
      ],
      "metadata": {
        "id": "PH1Eug3_h3V_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O1IZGQwXiKSp"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Memory"
      ],
      "metadata": {
        "id": "zScvnj5flbYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ChatMessageHistory"
      ],
      "metadata": {
        "id": "Wb2rUMfkldBO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#llm = ChatOpenAI(openai_api_key=userdata.get('OpenAI_Key'))"
      ],
      "metadata": {
        "id": "6PBlxSOklm8C"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = ChatMessageHistory()"
      ],
      "metadata": {
        "id": "CqkIdzaqlwFW"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.add_ai_message('Hi! Ask me anything about LangChain.')\n",
        "history.add_user_message('Describe a metaphor for learning LangChain in one sentence.')\n",
        "\n",
        "#response = llm.invoke(history.messages)\n",
        "#print(response.content)"
      ],
      "metadata": {
        "id": "64gYCaQUl3Z8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.add_user_message('Summarize the preceding sentence in fewer wwords')\n",
        "\n",
        "#response = llm.invoke(history.messages)"
      ],
      "metadata": {
        "id": "1CMOZgflueKv"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationChain"
      ],
      "metadata": {
        "id": "mUgi-muwvB3r"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(size=4)"
      ],
      "metadata": {
        "id": "Slx70mWpvXUt"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buffer_chain = ConversationChain(llm=llm, memory=memory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U0LlxpovwyQ",
        "outputId": "994e9a9b-3f3e-4111-e3b4-794c4439ebb2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use RunnableWithMessageHistory: https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# buffer_chain.invoke('Describe a language model in one sentence')\n",
        "# buffer_chain.invoke('Describe it again using less words')\n",
        "# buffer_chain.invoke('Describe it again fewer words but at least one word')\n",
        "# buffer_chain.invoke('What did I first ask you? I forgot.')"
      ],
      "metadata": {
        "id": "YKft4gdwv3-C"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationSummaryMemory"
      ],
      "metadata": {
        "id": "YTo1VVZwwd9h"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationSummaryMemory(llm=ChatOpenAI(openai_api_key=userdata.get('OpenAI_Key')))"
      ],
      "metadata": {
        "id": "TXPC9jXnw7cI"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_chain = ConversationChain(llm=llm, memory=memory, verbose=True)"
      ],
      "metadata": {
        "id": "mUUCXkRkxSNW"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summary_chain.invoke('Please summarize the future in 2 sentences.')\n",
        "# summary_chain.invoke('Why?')\n",
        "# summary_chain.invoke('What will I need to shape this?')"
      ],
      "metadata": {
        "id": "gwGwEtQIxsDZ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HeLUIGV-yn5a"
      },
      "execution_count": 44,
      "outputs": []
    }
  ]
}